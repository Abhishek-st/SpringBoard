{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(IDs, yields, batch_size, cutoff=None):\n",
    "    import numpy as np\n",
    "    import random\n",
    "    \n",
    " # Create empty arrays to contain batch of features and labels#\n",
    "\n",
    "    if cutoff != None:\n",
    "        batch_features = np.zeros((batch_size, cutoff, 1, 128, 11))\n",
    "        batch_yields = np.zeros((batch_size))\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                # choose random index in features\n",
    "                index = random.choice(range(len(IDs)))\n",
    "                ID = IDs[index]\n",
    "                if np.sum(np.isnan(np.load('data/PROCESSED_III/' + ID + '.npy'))) == 0:\n",
    "                    batch_features[i, :, :, :, :] = np.load('data/PROCESSED_III/' + ID + '.npy')[:cutoff, :, :, :]\n",
    "                    #print('yes', ID)\n",
    "                    batch_yields[i] = yields[ID]\n",
    "                else:\n",
    "                    print('no', ID)\n",
    "                    \n",
    "            yield batch_features, batch_yields\n",
    "                    \n",
    "    else:\n",
    "        batch_features = np.zeros((batch_size, 38, 1, 128, 11))\n",
    "        batch_yields = np.zeros((batch_size))\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                # choose random index in features\n",
    "                index = random.choice(range(len(IDs)))\n",
    "                ID = IDs[index]\n",
    "                if np.sum(np.isnan(np.load('data/PROCESSED_III/' + ID + '.npy'))) == 0:\n",
    "                    batch_features[i, :, :, :, :] = np.load('data/PROCESSED_III/' + ID + '.npy')\n",
    "                    #print('yes', ID)\n",
    "                    batch_yields[i] = yields[ID]\n",
    "                else:\n",
    "                    print('no', ID)\n",
    "            yield batch_features, batch_yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "model_list = ['CNN_LSTM', 'SepCNN_LSTM', 'CONVLSTM', 'CONV3D', 'CONVLSTM_CONV3D']\n",
    "\n",
    "# Datasets\n",
    "yields = pickle.load(open('data/yields.p', 'rb'))\n",
    "y = yields\n",
    "\n",
    "# define early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, \\\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 38, 1, 128, 11)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 38, 4096)          18112     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 38, 256)           4457472   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 38, 64)            16448     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2432)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2432)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2433      \n",
      "=================================================================\n",
      "Total params: 4,494,465\n",
      "Trainable params: 4,486,145\n",
      "Non-trainable params: 8,320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/phongpre/anaconda3-singularity/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/mnt/home/phongpre/anaconda3-singularity/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=84.5625, verbose=0, steps_per_epoch=1, epochs=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 38, 1, 128, 11)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 38, 4096)          17430     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 38, 256)           4457472   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 38, 64)            16448     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2432)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2432)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 2433      \n",
      "=================================================================\n",
      "Total params: 4,493,783\n",
      "Trainable params: 4,485,463\n",
      "Non-trainable params: 8,320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Loading Model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 38, 1, 128, 64)    38656     \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 38, 1, 128, 32)    24704     \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)  (None, 38, 1, 128, 32)    16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 38, 1, 128, 32)    128       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 155648)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4980768   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,060,801\n",
      "Trainable params: 5,060,737\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Loading Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 38, 1, 128, 64)    1472      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 38, 1, 128, 32)    4128      \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 38, 1, 128, 32)    2080      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 37, 1, 128, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 37, 1, 128, 32)    128       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 151552)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                4849696   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,857,537\n",
      "Trainable params: 4,857,473\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/phongpre/Springboard/model.py:140: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 1, 1), strides=(1, 1, 1), padding=\"valid\")`\n",
      "  border_mode='valid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_4 (ConvLSTM2D)  (None, 38, 1, 128, 64)    38656     \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_5 (ConvLSTM2D)  (None, 38, 1, 128, 32)    24704     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 38, 1, 128, 32)    2080      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 38, 1, 64, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 77824)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 77824)             311296    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                4980800   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,357,601\n",
      "Trainable params: 5,201,953\n",
      "Non-trainable params: 155,648\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# training model on data of year 2010-2015 (6 years total)\n",
    "\n",
    "model_list = ['CNN_LSTM', 'SepCNN_LSTM', 'CONVLSTM', 'CONV3D', 'CONVLSTM_CONV3D']\n",
    "\n",
    "# Datasets\n",
    "yields = pickle.load(open('data/yields.p', 'rb'))\n",
    "y = yields\n",
    "print(len(yields['train']), len(yields['validation']))\n",
    "\n",
    "# define early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, \\\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]\n",
    "\n",
    "# Generators\n",
    "training_generator = generator(list(y['train'].keys()), y['train'], 16)\n",
    "validation_generator = generator(list(y['validation'].keys()), y['validation'], 16)\n",
    "\n",
    "for model_name in model_list:\n",
    "    rm = ResearchModels(model_name, 38, (1, 128, 11), print_model=True)\n",
    "    rm.model.fit_generator(training_generator, validation_data=validation_generator, callbacks=callbacks_list,\\\n",
    "                               validation_steps=1353/16, samples_per_epoch=50, nb_epoch=100, verbose=0)\n",
    "    rm.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model CNN_LSTM\n",
      "1353/1353 [==============================] - 16s 12ms/step\n",
      "For model CNN_LSTM, the test mean absolute error is 18.85.\n",
      "Loading model SepCNN_LSTM\n",
      "1353/1353 [==============================] - 16s 12ms/step\n",
      "For model SepCNN_LSTM, the test mean absolute error is 24.11.\n",
      "Loading model CONVLSTM\n",
      "1353/1353 [==============================] - 65s 48ms/step\n",
      "For model CONVLSTM, the test mean absolute error is 16.20.\n",
      "Loading model CONV3D\n",
      "1353/1353 [==============================] - 30s 22ms/step\n",
      "For model CONV3D, the test mean absolute error is 96.39.\n",
      "Loading model CONVLSTM_CONV3D\n",
      "1353/1353 [==============================] - 57s 42ms/step\n",
      "For model CONVLSTM_CONV3D, the test mean absolute error is 36.14.\n",
      "The best model is CONVLSTM.\n"
     ]
    }
   ],
   "source": [
    "# Evalurate model on the yields of corn yields across U.S. in year 2016\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "test_gen = generator(list(yields['validation'].keys()), yields['validation'], len(yields['validation']))\n",
    "X_test, y_test = next(test_gen)\n",
    "abs_error = np.empty(len(model_list))\n",
    "\n",
    "for i, model_name in enumerate(model_list):\n",
    "    rm = ResearchModels('No model', 38, (1, 128, 11), saved_model=model_name)\n",
    "    abs_error[i] = rm.model.evaluate(X_test, y_test, batch_size=16)[1]\n",
    "    print('For model {}, the test mean absolute error is {:.2f}.'.format(model_name, abs_error[i]))\n",
    "\n",
    "best_model = model_list[np.argmin(abs_error)]\n",
    "print('The best model is {}.'.format(best_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model CONVLSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/phongpre/anaconda3-singularity/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/mnt/home/phongpre/anaconda3-singularity/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=169.125, verbose=0, steps_per_epoch=50, epochs=100)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: early stopping\n",
      "1353/1353 [==============================] - 66s 48ms/step\n",
      "For batch 8, the test mean absolute error is 61.92.\n",
      "Loading model CONVLSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/phongpre/anaconda3-singularity/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=42.28125, verbose=0, steps_per_epoch=50, epochs=100)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "1353/1353 [==============================] - 63s 47ms/step\n",
      "For batch 32, the test mean absolute error is 17.17.\n",
      "Loading model CONVLSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/phongpre/anaconda3-singularity/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=21.140625, verbose=0, steps_per_epoch=50, epochs=100)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: early stopping\n",
      "1353/1353 [==============================] - 64s 47ms/step\n",
      "For batch 64, the test mean absolute error is 20.10.\n"
     ]
    }
   ],
   "source": [
    "batch_size = [8, 32, 64]\n",
    "abs_error_batch = np.empty(len(batch_size))\n",
    "\n",
    "for i, size in enumerate(batch_size):\n",
    "    # Generators\n",
    "    training_generator = generator(list(y['train'].keys()), y['train'], size)\n",
    "    validation_generator = generator(list(y['validation'].keys()), y['validation'], size)\n",
    "\n",
    "    rm = ResearchModels('None', 38, (1, 128, 11), saved_model=best_model)\n",
    "    rm.model.fit_generator(training_generator, validation_data=validation_generator, callbacks=callbacks_list,\\\n",
    "                               validation_steps=1353/size, samples_per_epoch=50, nb_epoch=100, verbose=0)\n",
    "\n",
    "    abs_error_batch[i] = rm.model.evaluate(X_test, y_test, batch_size=size)[1]\n",
    "    print('For batch {}, the test mean absolute error is {:.2f}.'.format(size, abs_error_batch[i]))\n",
    "    \n",
    "    rm.model.save(best_model + '_' + str(size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing the number of frames per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing 1 frames per year\n",
      "Loading Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/phongpre/anaconda3-singularity/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/home/phongpre/anaconda3-singularity/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=84.5625, verbose=0, steps_per_epoch=50, epochs=100)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: early stopping\n",
      "1353/1353 [==============================] - 1s 524us/step\n",
      "For 1 frames per year, the test mean absolute error is 79.35.\n",
      "Doing 5 frames per year\n",
      "Loading Model.\n",
      "Epoch 00017: early stopping\n",
      "1353/1353 [==============================] - 9s 6ms/step\n",
      "For 5 frames per year, the test mean absolute error is 59.80.\n",
      "Doing 10 frames per year\n",
      "Loading Model.\n",
      "Epoch 00008: early stopping\n",
      "1353/1353 [==============================] - 17s 12ms/step\n",
      "For 10 frames per year, the test mean absolute error is 56.49.\n",
      "Doing 15 frames per year\n",
      "Loading Model.\n",
      "Epoch 00010: early stopping\n",
      "1353/1353 [==============================] - 26s 19ms/step\n",
      "For 15 frames per year, the test mean absolute error is 27.07.\n",
      "Doing 20 frames per year\n",
      "Loading Model.\n",
      "Epoch 00025: early stopping\n",
      "1353/1353 [==============================] - 33s 25ms/step\n",
      "For 20 frames per year, the test mean absolute error is 22.55.\n",
      "Doing 25 frames per year\n",
      "Loading Model.\n",
      "Epoch 00014: early stopping\n",
      "1353/1353 [==============================] - 42s 31ms/step\n",
      "For 25 frames per year, the test mean absolute error is 23.16.\n",
      "Doing 30 frames per year\n",
      "Loading Model.\n",
      "Epoch 00009: early stopping\n",
      "1353/1353 [==============================] - 50s 37ms/step\n",
      "For 30 frames per year, the test mean absolute error is 16.83.\n",
      "Doing 35 frames per year\n",
      "Loading Model.\n",
      "Epoch 00016: early stopping\n",
      "1353/1353 [==============================] - 59s 43ms/step\n",
      "For 35 frames per year, the test mean absolute error is 19.92.\n"
     ]
    }
   ],
   "source": [
    "n_frames = [1, 5, 10, 15, 20, 25, 30, 35]\n",
    "abs_error_frames = np.empty(len(n_frames))\n",
    "i = 0\n",
    "\n",
    "for frame in n_frames:\n",
    "    # Generators\n",
    "    print('Doing {} frames per year'.format(frame))\n",
    "    training_generator = generator(list(y['train'].keys()), y['train'], 16, cutoff=frame)\n",
    "    validation_generator = generator(list(y['validation'].keys()), y['validation'], 16, cutoff=frame)\n",
    "    \n",
    "    test_gen = generator(list(yields['validation'].keys()), yields['validation'], len(yields['validation']), cutoff=frame)\n",
    "    X_test, y_test = next(test_gen)\n",
    "\n",
    "    rm = ResearchModels('CONVLSTM', frame, (1, 128, 11))\n",
    "    rm.model.fit_generator(training_generator, validation_data=validation_generator, callbacks=callbacks_list,\\\n",
    "                               validation_steps=1353/16, samples_per_epoch=50, nb_epoch=100, verbose=0)\n",
    "    abs_error_frames[i] = rm.model.evaluate(X_test, y_test, batch_size=16)[1]\n",
    "    \n",
    "    rm.model.save('CONVLSTM' + '_' + str(frame))\n",
    "    print('For {} frames per year, the test mean absolute error is {:.2f}.'.format(frame, abs_error_frames[i]))\n",
    "    i += 1\n",
    "    pickle.dump( abs_error_frames, open( \"abs_error_framess.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
